{"paragraphs":[{"text":"%md\n#Extractions de features\nVariables nécessaires pour la prediction (on utilise pour l'instant les variables prédictives simples - sans transformation à effectuer) : \n- Pclass, sex ,age,SibSp,Parch,Fare,embarked, survived","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:17:35 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936673_-1095345527","id":"20160309-205536_1770451134","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Extractions de features</h1>\n<p>Variables nécessaires pour la prediction (on utilise pour l'instant les variables prédictives simples - sans transformation à effectuer) :</p>\n<ul>\n<li>Pclass, sex ,age,SibSp,Parch,Fare,embarked, survived</li>\n</ul>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:17:35 PM","dateFinished":"Mar 9, 2016 10:17:35 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1887"},{"text":"%md\nCas des valeurs incohérentes : \nVu dans le notebook 1, un certain nombre de lignes contienne un age null et fare à 0.\n__Nous prenons le choix pour un premier essai d'exclure les lignes avec age=null & fare=0__","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:17:37 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936673_-1095345527","id":"20160309-205536_895511170","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Cas des valeurs incohérentes :\n<br  />Vu dans le notebook 1, un certain nombre de lignes contienne un age null et fare à 0.\n<br  /><strong>Nous prenons le choix pour un premier essai d'exclure les lignes avec age=null &amp; fare=0</strong></p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:17:37 PM","dateFinished":"Mar 9, 2016 10:17:37 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1888"},{"title":"Selection des données","text":"val df = sqlContext.sql(\"select Pclass, sex ,age,SibSp,Parch,Fare,embarked , Double(survived) survived from titanic where age is not null and fare!=0 \")\ndf.show(5)\n","dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936673_-1095345527","id":"20160309-205536_295889796","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1889"},{"title":"API Spark utilisé","text":"%angular\nNous allons utiliser l'API Spark <a href=\"http://spark.apache.org/docs/latest/ml-guide.html\">spark.ml</a>","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:17:41 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","title":true,"editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457558404198_-691476318","id":"20160309-212004_1765786447","result":{"code":"SUCCESS","type":"ANGULAR","msg":"Nous allons utiliser l'API Spark <a href=\"http://spark.apache.org/docs/latest/ml-guide.html\">spark.ml</a>"},"dateCreated":"Mar 9, 2016 9:20:04 PM","dateStarted":"Mar 9, 2016 10:17:41 PM","dateFinished":"Mar 9, 2016 10:17:41 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1890"},{"text":"%md\n\n###Input /Output algo ML\nLes algorithme ML de spark prennent en entrée __un tableau de Double__ ex : [12.3 23.0 13.0...] ==> les features \nLes algorithme ML de spark prédise un __Double__ ex : 1.0 ==> Survivant","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:17:44 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936674_-1094191280","id":"20160309-205536_1686229077","result":{"code":"SUCCESS","type":"HTML","msg":"<h3>Input /Output algo ML</h3>\n<p>Les algorithme ML de spark prennent en entrée <strong>un tableau de Double</strong> ex : [12.3 23.0 13.0&hellip;] ==> les features\n<br  />Les algorithme ML de spark prédise un <strong>Double</strong> ex : 1.0 ==> Survivant</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:17:44 PM","dateFinished":"Mar 9, 2016 10:17:44 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1891"},{"text":"%md\nNotre datset contient des String (Sex et Embarked) qu'il va falloir transformer en Double\nSurvived est un Int qu'il va faloir convertir en Double","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:17:45 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936674_-1094191280","id":"20160309-205536_987553659","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Notre datset contient des String (Sex et Embarked) qu'il va falloir transformer en Double\n<br  />Survived est un Int qu'il va faloir convertir en Double</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:17:45 PM","dateFinished":"Mar 9, 2016 10:17:45 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1892"},{"text":"%md\nPour convertir un String en Double utilisation de la fonction Spark native  StringIndexer() qui ajoute un champ Double au DataFrame","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:17:47 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936674_-1094191280","id":"20160309-205536_215914200","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Pour convertir un String en Double utilisation de la fonction Spark native  StringIndexer() qui ajoute un champ Double au DataFrame</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:17:47 PM","dateFinished":"Mar 9, 2016 10:17:47 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1893"},{"title":"Creation de la variable indexedSex","text":"import org.apache.spark.ml.feature.StringIndexer\n\nval sexIndexer = new StringIndexer()\n  .setInputCol(\"sex\")\n  .setOutputCol(\"indexedSex\")\n  .fit(df)\n  \n val debugDFSexIndexed = sexIndexer.transform(df)//Debug regarder comment est transformer la variable sex\n debugDFSexIndexed.select(\"sex\",\"indexedSex\").show(3)","dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936675_-1094576029","id":"20160309-205536_178692620","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1894"},{"text":"%md\nFaire de même pour la colonne  embarked : la transformer en la variable indexedEmbarked","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:17:52 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936675_-1094576029","id":"20160309-205536_1624230005","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Faire de même pour la colonne  embarked : la transformer en la variable indexedEmbarked</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:17:52 PM","dateFinished":"Mar 9, 2016 10:17:52 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1895"},{"title":"Création de la variable indexedEmbarked","text":"import org.apache.spark.ml.feature.StringIndexer\n\nval embarkedIndexer = <COMPLETER>\n  \n  \nval debugDFEmbarkedIndexed = embarkedIndexer.transform(debugDFSexIndexed)\n\ndebugDFEmbarkedIndexed.select(\"embarked\",\"indexedEmbarked\").show(3)","dateUpdated":"Mar 9, 2016 10:18:09 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936675_-1094576029","id":"20160309-205536_1010103312","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1896"},{"text":"%md\n#### Transfomation des features en tableau de Double ([12.3 24.4....])\nPour cela utilisation de la fonction Spark VectorAssembler","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:18:07 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936676_-1096499773","id":"20160309-205536_1151651096","result":{"code":"SUCCESS","type":"HTML","msg":"<h4>Transfomation des features en tableau de Double ([12.3 24.4&hellip;.])</h4>\n<p>Pour cela utilisation de la fonction Spark VectorAssembler</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:18:07 PM","dateFinished":"Mar 9, 2016 10:18:07 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1897"},{"title":"Création de la variable \"features\"","text":"import org.apache.spark.ml.feature.VectorAssembler\n\nval assembler = new VectorAssembler()\n  .setInputCols(Array(\"Pclass\",\"indexedSex\" ,\"age\",\"SibSp\",\"Parch\",\"Fare\",\"indexedEmbarked\"))\n  .setOutputCol(\"features\")\n  \n  \n  val debugFeaturesDF =   assembler.transform(debugDFEmbarkedIndexed)\n  \n  debugFeaturesDF.registerTempTable(\"featuresDF\")\n  ","dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936676_-1096499773","id":"20160309-205536_2074976578","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1898"},{"text":"%sql\nselect * from featuresDF limit 2","dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936676_-1096499773","id":"20160309-205536_1707033122","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1899"},{"text":"%md\nSpark necessite de tranformer le label avec IndexedLabel pour obtenir des metadonnées sur le label ","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:18:18 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936677_-1096884522","id":"20160309-205536_2125512433","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Spark necessite de tranformer le label avec IndexedLabel pour obtenir des metadonnées sur le label</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:18:18 PM","dateFinished":"Mar 9, 2016 10:18:18 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1900"},{"text":"val labelIndexer = new StringIndexer()\n  .setInputCol(\"survived\")\n  .setOutputCol(\"survivedIndexed\")\n  .fit(df)","dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936677_-1096884522","id":"20160309-205536_480145458","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1901"},{"text":"%md\nVariable prédictive : features\nVariable cible : survived","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:18:23 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936678_-1095730276","id":"20160309-205536_170882386","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Variable prédictive : features\n<br  />Variable cible : survived</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:18:23 PM","dateFinished":"Mar 9, 2016 10:18:23 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1902"},{"text":"%md\n#Definition du modèle\nNous prenons le choix de tester une regression logistique","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:18:29 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936678_-1095730276","id":"20160309-205536_362715239","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Definition du modèle</h1>\n<p>Nous prenons le choix de tester une regression logistique</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:18:29 PM","dateFinished":"Mar 9, 2016 10:18:29 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1903"},{"text":"%angular\n<h2>Logistic regression</h2>\n<img src=\"http://mlpy.sourceforge.net/docs/3.5/_images/elasticnetc.png\"/>\n<img src=\"https://codesachin.files.wordpress.com/2015/08/linearly_separable_4.png\"/>\nRouge : Survivant\n<br/>\nBleu : non survivant\n<br/>\n<b>Notre modèle va permettre de definir cette frontière entre les deux zones </b>","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:18:35 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936678_-1095730276","id":"20160309-205536_1847786259","result":{"code":"SUCCESS","type":"ANGULAR","msg":"<h2>Logistic regression</h2>\n<img src=\"http://mlpy.sourceforge.net/docs/3.5/_images/elasticnetc.png\"/>\n<img src=\"https://codesachin.files.wordpress.com/2015/08/linearly_separable_4.png\"/>\nRouge : Survivant\n<br/>\nBleu : non survivant\n<br/>\n<b>Notre modèle va permettre de definir cette frontière entre les deux zones </b>"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:18:34 PM","dateFinished":"Mar 9, 2016 10:18:34 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1904"},{"text":"%angular\nDocumentation spark du  <a href=\"http://spark.apache.org/docs/1.5.2/api/scala/index.html#org.apache.spark.ml.classification.LogisticRegression\">modèle</a> ","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:18:45 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457558560678_1603412954","id":"20160309-212240_2105035483","result":{"code":"SUCCESS","type":"ANGULAR","msg":"Documentation spark du  <a href=\"http://spark.apache.org/docs/1.5.2/api/scala/index.html#org.apache.spark.ml.classification.LogisticRegression\">modèle</a>"},"dateCreated":"Mar 9, 2016 9:22:40 PM","dateStarted":"Mar 9, 2016 10:18:43 PM","dateFinished":"Mar 9, 2016 10:18:43 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1905"},{"text":"import org.apache.spark.ml.classification.LogisticRegression\n\nval model = new LogisticRegression()\n  .setMaxIter(40)\n  .setFeaturesCol(\"features\")\n.setLabelCol(\"survivedIndexed\")\n  ","dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936679_-1096115024","id":"20160309-205536_22153477","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1906"},{"text":"%md\n#Definition du Workfow de transformation (Pipeline)\n\nLes étapes de transformation : \n- Transformer sex en Double (via le transformer sexIndexer). sex => indexedSex\n- Transformer embarked en Double (via le transformer embarkedIndexer). embarked=> indexedEmbarked \n- Transformer Pclass,indexedSex ,age,SibSp,Parch,Fare,indexedEmbarked  en tableau de Double (via le transformer assembler) : Pclass,indexedSex ,age,SibSp,Parch,Fare,indexedEmbarked => Features\n- Transformer label en Double (via le transformer labelIndexer). label=> survivedIndexed\n- Estimer le modèle via les variable features et survivedIndexed (via l'estimator model)","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:18:52 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936679_-1096115024","id":"20160309-205536_1881565592","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Definition du Workfow de transformation (Pipeline)</h1>\n<p>Les étapes de transformation :</p>\n<ul>\n<li>Transformer sex en Double (via le transformer sexIndexer). sex => indexedSex</li>\n<li>Transformer embarked en Double (via le transformer embarkedIndexer). embarked=> indexedEmbarked</li>\n<li>Transformer Pclass,indexedSex ,age,SibSp,Parch,Fare,indexedEmbarked  en tableau de Double (via le transformer assembler) : Pclass,indexedSex ,age,SibSp,Parch,Fare,indexedEmbarked => Features</li>\n<li>Transformer label en Double (via le transformer labelIndexer). label=> survivedIndexed</li>\n<li>Estimer le modèle via les variable features et survivedIndexed (via l'estimator model)</li>\n</ul>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:18:52 PM","dateFinished":"Mar 9, 2016 10:18:52 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1907"},{"text":"import org.apache.spark.ml.Pipeline\n\nval pipeline = new Pipeline()\n  .setStages(Array(sexIndexer,embarkedIndexer,assembler,labelIndexer,  model))","dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936679_-1096115024","id":"20160309-205536_286952027","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1908"},{"text":"%md \nPasser au notebook 3 : entrainement et analyse du modèle","authenticationInfo":{},"dateUpdated":"Mar 9, 2016 10:19:09 PM","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936680_-1098038769","id":"20160309-205536_1754857736","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Passer au notebook 3 : entrainement et analyse du modèle</p>\n"},"dateCreated":"Mar 9, 2016 8:55:36 PM","dateStarted":"Mar 9, 2016 10:19:10 PM","dateFinished":"Mar 9, 2016 10:19:10 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1909"},{"dateUpdated":"Mar 9, 2016 8:55:36 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1457556936680_-1098038769","id":"20160309-205536_2031232831","dateCreated":"Mar 9, 2016 8:55:36 PM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1910"}],"name":"02 - Titanic : Construire le modèle","id":"2BEVNMGS9","owners":[],"readers":[],"writers":[],"angularObjects":{"2BDGS26KH":[],"2BFKU3YF6":[],"2BFY4UKAS":[],"2BCYUSJ27":[]},"config":{"looknfeel":"default"},"info":{}}